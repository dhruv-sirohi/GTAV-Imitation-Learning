{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Train_GTA5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28fr9Fy1k8yH"
      },
      "source": [
        "Note: must turn off radar in settings before recording"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNkuehuqjPe9",
        "outputId": "a317d85c-9e9f-4fb4-cc44-64329dd4c7c7"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#imports + file upload\n",
        "print(\"need to prune imports\")\n",
        "#h+=1\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Activation,Dropout,Flatten,Conv2D,MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "assert len(tf.config.list_physical_devices('GPU')) > 0\n",
        "\n",
        "from google.colab import files\n",
        "from skimage.color import rgb2gray\n",
        "from collections import Counter\n",
        "from random import shuffle\n",
        "import cv2\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt \n",
        "#uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "need to prune imports\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lu6X4MSkTQL"
      },
      "source": [
        "#data processing\n",
        "\n",
        "#next steps: use GAN to debias dataset (MIT 6.S191 lec 4, lab 2)\n",
        "\n",
        "def data_processing(start_val,num_files):\n",
        "  s_turn = []\n",
        "  m_turn = []\n",
        "  adj_turn = []\n",
        "  no_turn = []\n",
        "  balanced_data = []\n",
        "  starting_value = start_val\n",
        "  continue_loop = True\n",
        "  #start_time = time.time()\n",
        "  while continue_loop:\n",
        "    data_file_name = '/content/drive/MyDrive/GTA Driving Data/processed-training_data-{}.npy'.format(starting_value)\n",
        "    if os.path.isfile(data_file_name) and starting_value < start_val + num_files:\n",
        "      print(starting_value)\n",
        "      starting_value += 1\n",
        "      processed_data = np.load(data_file_name,allow_pickle=True)    \n",
        "      #print(len(processed_data))\n",
        "      #h+= 1\n",
        "      #i = 0\n",
        "      for entry in processed_data:\n",
        "        #print(i)\n",
        "        #i += 1\n",
        "        #np_entry =print(entry[0])\n",
        "        y = entry[0][0:3]\n",
        "        y_ls = y[2]\n",
        "        x= entry[1]\n",
        "        #x = rgb2gray(entry[1])\n",
        "        #flipping images\n",
        "        y_flipped = [y[0],y[1],1-y_ls]\n",
        "        x_flipped = cv2.flip(x, 1)\n",
        "        #print(y_ls)\n",
        "        if (y_ls > 0.875 or y_ls < 0.125):\n",
        "          #very sharp turn, but it doesn't warrant its own array\n",
        "          s_turn.append([x,y])\n",
        "          #s_turn.append([x_flipped,y_flipped])\n",
        "        elif (y_ls > 0.8 or y_ls < 0.2):\n",
        "          #sharp turn\n",
        "          #s_turn.append([x_flipped,y_flipped])\n",
        "          s_turn.append([x,y])\n",
        "        elif (y_ls > 0.7 or y_ls < 0.3):\n",
        "          #medium turn\n",
        "          m_turn.append([x,y])\n",
        "          #m_turn.append([x_flipped,y_flipped])\n",
        "\n",
        "        elif (y_ls > 0.65 or y_ls < 0.35):\n",
        "          #light turn, doesn't warrant its own array\n",
        "          m_turn.append([x,y])\n",
        "          #m_turn.append([x_flipped,y_flipped])\n",
        "\n",
        "        elif (y_ls > 0.575 or y_ls < 0.425):\n",
        "          #adjustments\n",
        "          adj_turn.append([x,y])\n",
        "          #adj_turn.append([x_flipped,y_flipped])\n",
        "        else:\n",
        "          #no turn\n",
        "          no_turn.append([x,y])\n",
        "          #no_turn.append([x_flipped,y_flipped])\n",
        "    else:\n",
        "      if not (starting_value < start_val + num_files):\n",
        "        continue_loop = False\n",
        "      else:\n",
        "        starting_value += 1\n",
        "\n",
        "  shuffle(no_turn)\n",
        "  #without shuffling, array adjustment in next step would mean that the training set is full of mirror repeats \n",
        "  #we would prefer to have [img12_mirrored,img1] rather than [img1_mirrored, img1]\n",
        "  #shuffling allows for this\n",
        "\n",
        "  balanced_data = s_turn + m_turn + adj_turn + no_turn[0:len(adj_turn)]\n",
        "  #we want agent to make small adjustments, so adj_turn isn't being adjusted\n",
        "  #we don't want agent to just go straight, so less of no_turn is being added\n",
        "  \n",
        "\n",
        "  \"\"\"\n",
        "  arr_lengths = [len(adj_turn),len(adj_turn),len(m_turn),len(s_turn)]\n",
        "  arr_names = [\"no turn (trimmed)\",\"adjustment turn\",\"medium turn\", \"sharp turn\"]\n",
        "  \n",
        "  plt.bar(arr_names,arr_lengths)\n",
        "  plt.show()\n",
        "  \"\"\"\n",
        "\n",
        "  no_turn = []\n",
        "  s_turn = []\n",
        "  m_turn = []\n",
        "  adj_turn = []\n",
        "  shuffle(balanced_data)\n",
        "  X = []\n",
        "  Y = []\n",
        "  for entry in balanced_data:\n",
        "    entry[0] = rgb2gray(entry[0])\n",
        "\n",
        "\n",
        "  X , Y = zip(*balanced_data)\n",
        "\n",
        "  print(\"done! have {} test cases\".format(len(balanced_data)))\n",
        "  #print(\"time to run time: {}\".format(time.time()-start_time))\n",
        "  balanced_data = []\n",
        "\n",
        "  X_train_3dim = tf.convert_to_tensor(X)\n",
        "  new_shape = list(X_train_3dim.shape) + [1]\n",
        "  X_train = tf.reshape(X_train_3dim,new_shape)\n",
        "\n",
        "  Y_train_3dim = tf.convert_to_tensor(Y)\n",
        "  new_shape = list(Y_train_3dim.shape) + [1]\n",
        "  Y_train = tf.transpose(tf.reshape(Y_train_3dim,new_shape),perm = [0,2,1])\n",
        "  \n",
        "  return X_train,Y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SzgDspAwdbu"
      },
      "source": [
        "#saving chunk of training data as testing data (now irrelevant)\n",
        "\n",
        "#PERCENT_TEST = 20\n",
        "\n",
        "#test_index_start = int(PERCENT_TEST*len(balanced_data)/100)\n",
        "#train_data = balanced_data[:-test_index_start]\n",
        "#test_data = balanced_data[-test_index_start:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwYKIJtKtsPl",
        "outputId": "d1abaf23-389b-4d57-90fc-3b284044d588"
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "import mxnet as mx\n",
        "from mxnet import np, npx\n",
        "from mxnet.gluon import nn\n",
        "from d2l import mxnet as d2l\n",
        "\"\"\"\n",
        "\n",
        "#set up alexnet\n",
        "\n",
        "\n",
        "def build_alexnet_model():\n",
        "  #image_shape = (80,60,1)\n",
        "  np.random.seed(1000)\n",
        "  #https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputLayer\n",
        "  model = tf.keras.Sequential([\n",
        "    #tf.keras.layers.InputLayer(input_shape=image_shape),\n",
        "    tf.keras.layers.Conv2D(filters=96, kernel_size=(5,5),strides=(2,2),activation=tf.nn.relu), \n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(3,3),strides=(2,2)),\n",
        "    tf.keras.layers.Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),activation=tf.nn.relu), \n",
        "    #tf.keras.layers.MaxPooling2D(pool_size=(3,3),strides=(2,2)),\n",
        "    #tf.keras.layers.Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),activation=tf.nn.relu), \n",
        "    tf.keras.layers.Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),activation=tf.nn.relu), \n",
        "    tf.keras.layers.Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),activation=tf.nn.relu), \n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(3,3),strides=(2,2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(4096, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(4096, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(3, activation=tf.keras.activations.linear)])\n",
        "  \n",
        "  return model\n",
        "\n",
        "def build_cnn_model():\n",
        "      cnn_model = tf.keras.Sequential([\n",
        "        # Here, we use a larger 11 x 11 window to capture objects. At the same\n",
        "        # time, we use a stride of 2 to reduce the height and width of\n",
        "        # the output.\n",
        "        tf.keras.layers.Conv2D(filters=96, kernel_size=11, strides=2),\n",
        "        tf.keras.layers.Activation('relu'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
        "        #tf.keras.layers.BatchNormalization(axis=3),\n",
        "        # Make the convolution window smaller, set padding to 2 for consistent\n",
        "        # height and width across the input and output, and increase the\n",
        "        # number of output channels\n",
        "        tf.keras.layers.Conv2D(filters=256, kernel_size=5, padding='same',\n",
        "                               activation='relu'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
        "        #tf.keras.layers.BatchNormalization(),\n",
        "        # Use three successive convolutional layers and a smaller convolution\n",
        "        # window. Except for the final convolutional layer, the number of\n",
        "        # output channels is further increased. Pooling layers are not used to\n",
        "        # reduce the height and width of input after the first two\n",
        "        # convolutional layers\n",
        "        tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding='same',\n",
        "                               activation='relu'),\n",
        "        #tf.keras.layers.BatchNormalization(axis=-1),\n",
        "        tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding='same',\n",
        "                               activation='relu'),\n",
        "        #tf.keras.layers.BatchNormalization(axis=-1),\n",
        "        tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same',\n",
        "                               activation='relu'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
        "        #tf.keras.layers.BatchNormalization(axis=-1),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        #tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(4096, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(4096, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        # Output layer. Because control vector is made up of 3 values, \n",
        "        # this dense layer is made up of only 3 units\n",
        "        tf.keras.layers.Dense(3)])\n",
        "      \n",
        "      return cnn_model\n",
        "\n",
        "\n",
        "#x = np.random.rand(2,160,120,1)\n",
        "#X = tf.convert_to_tensor(x)\n",
        "\n",
        "# Initialize the model by passing some data through\n",
        "#predictions = cnn_model.predict(X_train_0)\n",
        "#print(predictions)\n",
        "#print(predictions.shape)\n",
        "# Print the summary of the layers in the model.\n",
        "#print(cnn_model.summary())\n",
        "\n",
        "#load cnn model, load arrays\n",
        "time_vals = []\n",
        "train_accuracy = []\n",
        "test_accuracy = []\n",
        "\n",
        "epoch_to_load = int(input(\"which epoch to load?\"))\n",
        "if epoch_to_load > 0:\n",
        "  cnn_model = tf.keras.models.load_model('/content/drive/MyDrive/GTA Driving Data/training weights/gta_cnn_model_epoch_{}.h5'.format(epoch_to_load))\n",
        "  graph_data = np.load('/content/drive/MyDrive/GTA Driving Data/progress data/graph_data.npy',allow_pickle=True)\n",
        "  time_vals = graph_data[0][0:epoch_to_load].tolist()\n",
        "  train_accuracy = graph_data[1][0:epoch_to_load].tolist()\n",
        "  test_accuracy = graph_data[2][0:epoch_to_load].tolist()\n",
        "  print(type(time_vals))\n",
        "  print(time_vals)\n",
        "\n",
        "else:\n",
        "  cnn_model = build_cnn_model()\n",
        "  cnn_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-1), \n",
        "                loss=tf.keras.losses.MeanSquaredError(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 48\n",
        "\n",
        "files_in_epoch = 0\n",
        "accuracy_store = 0\n",
        "start_val = 0\n",
        "num_files_to_retrieve = 10\n",
        "num_files_to_test = 200\n",
        "for epoch in range(epoch_to_load+1,EPOCHS+1):\n",
        "  print('-------------STARTING EPOCH {}-------------'.format(epoch))\n",
        "  files_in_epoch = 0\n",
        "  accuracy_store = 0\n",
        "  while start_val < num_files_to_test-num_files_to_retrieve*3:\n",
        "    if(start_val < 83):\n",
        "      X_train, Y_train = data_processing(start_val,num_files_to_retrieve)\n",
        "      #print(\"len {}\".format(len(X_train)))\n",
        "      start_val += num_files_to_retrieve\n",
        "    else:\n",
        "      X_train, Y_train = data_processing(start_val,num_files_to_retrieve*3)\n",
        "      start_val += num_files_to_retrieve*3\n",
        "    \n",
        "    num_files = X_train.shape[0]\n",
        "    files_in_epoch += num_files\n",
        "\n",
        "    history = cnn_model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=1)#,callbacks=[cp_callback])\n",
        "    #weights accuracy by number of files it is measured over\n",
        "    group_accuracy = num_files*history.history['accuracy'][0]\n",
        "    accuracy_store += group_accuracy  \n",
        "\n",
        "  #train on tail end of dataset\n",
        "  X_train, Y_train = data_processing(start_val,num_files_to_test-start_val+1)\n",
        "\n",
        "  num_files = X_train.shape[0]\n",
        "  files_in_epoch += num_files\n",
        "\n",
        "  history = cnn_model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=1)#,callbacks=[cp_callback])\n",
        "  \n",
        "  group_accuracy = num_files*history.history['accuracy'][0]\n",
        "  accuracy_store += group_accuracy\n",
        "\n",
        "  #appends average epoch accuracy\n",
        "  train_accuracy.append(accuracy_store/(files_in_epoch))\n",
        "  time_vals.append(epoch)\n",
        "\n",
        "  X_test, Y_test = data_processing(201,33)\n",
        "  test_loss, test_acc = cnn_model.evaluate(X_test,Y_test)\n",
        "  print('Test accuracy:', test_acc)\n",
        "  test_accuracy.append(test_acc)\n",
        "\n",
        "  #saving model\n",
        "  if epoch % 16 == 0:\n",
        "    print(\"SAVED\")\n",
        "    file_name = \"/content/drive/MyDrive/GTA Driving Data/training weights/gta_cnn_model_epoch_{}.h5\".format(epoch)\n",
        "    cnn_model.save(file_name)\n",
        "    graph_data = [time_vals,train_accuracy,test_accuracy]\n",
        "    np.save('/content/drive/MyDrive/GTA Driving Data/progress data/graph_data.npy',graph_data)\n",
        "  \n",
        "  start_val = 0\n",
        "\n",
        "plt.plot(time_vals, test_accuracy, label = \"test accuracy\")\n",
        "plt.plot(time_vals, train_accuracy, label = \"train accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "which epoch to load?9\n",
            "<class 'list'>\n",
            "[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]\n",
            "-------------STARTING EPOCH 10-------------\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "done! have 10282 test cases\n",
            "322/322 [==============================] - 16s 50ms/step - loss: 0.0336 - accuracy: 0.7220\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "done! have 10096 test cases\n",
            "316/316 [==============================] - 16s 50ms/step - loss: 0.0454 - accuracy: 0.7198\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "done! have 10874 test cases\n",
            "340/340 [==============================] - 17s 50ms/step - loss: 0.0404 - accuracy: 0.7852\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "done! have 10861 test cases\n",
            "340/340 [==============================] - 17s 50ms/step - loss: 0.0559 - accuracy: 0.5825\n",
            "40\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "done! have 10164 test cases\n",
            "318/318 [==============================] - 16s 50ms/step - loss: 0.0470 - accuracy: 0.7642\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "done! have 8788 test cases\n",
            "275/275 [==============================] - 14s 50ms/step - loss: 0.0424 - accuracy: 0.8181\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "done! have 10929 test cases\n",
            "342/342 [==============================] - 17s 50ms/step - loss: 0.0418 - accuracy: 0.7284\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "done! have 9229 test cases\n",
            "289/289 [==============================] - 15s 50ms/step - loss: 0.0456 - accuracy: 0.6797\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "done! have 6183 test cases\n",
            "194/194 [==============================] - 10s 50ms/step - loss: 0.0526 - accuracy: 0.6736\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "done! have 10322 test cases\n",
            "323/323 [==============================] - 16s 50ms/step - loss: 0.0443 - accuracy: 0.7132\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "done! have 10819 test cases\n",
            "339/339 [==============================] - 17s 50ms/step - loss: 0.0611 - accuracy: 0.6529\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "done! have 9375 test cases\n",
            "293/293 [==============================] - 15s 50ms/step - loss: 0.0616 - accuracy: 0.6329\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "done! have 7232 test cases\n",
            "226/226 [==============================] - 11s 49ms/step - loss: 0.0381 - accuracy: 0.7757\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "done! have 10756 test cases\n",
            "337/337 [==============================] - 7s 22ms/step - loss: 0.0523 - accuracy: 0.7178\n",
            "Test accuracy: 0.7178214192390442\n",
            "-------------STARTING EPOCH 11-------------\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "done! have 10282 test cases\n",
            "322/322 [==============================] - 17s 51ms/step - loss: 0.0339 - accuracy: 0.7202\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "done! have 10096 test cases\n",
            "316/316 [==============================] - 17s 53ms/step - loss: 0.0450 - accuracy: 0.7187\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "done! have 10874 test cases\n",
            "340/340 [==============================] - 18s 53ms/step - loss: 0.0402 - accuracy: 0.7899\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "done! have 10861 test cases\n",
            "340/340 [==============================] - 18s 53ms/step - loss: 0.0557 - accuracy: 0.5815\n",
            "40\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "done! have 10164 test cases\n",
            "318/318 [==============================] - 17s 53ms/step - loss: 0.0469 - accuracy: 0.7638\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "done! have 8788 test cases\n",
            "275/275 [==============================] - 15s 53ms/step - loss: 0.0420 - accuracy: 0.8195\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "done! have 10929 test cases\n",
            "342/342 [==============================] - 18s 53ms/step - loss: 0.0420 - accuracy: 0.7268\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "done! have 9229 test cases\n",
            "289/289 [==============================] - 15s 53ms/step - loss: 0.0456 - accuracy: 0.6746\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "done! have 6183 test cases\n",
            "194/194 [==============================] - 10s 53ms/step - loss: 0.0520 - accuracy: 0.6810\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "done! have 10322 test cases\n",
            "323/323 [==============================] - 17s 53ms/step - loss: 0.0446 - accuracy: 0.7105\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "done! have 10819 test cases\n",
            "339/339 [==============================] - 18s 53ms/step - loss: 0.0612 - accuracy: 0.6523\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "done! have 9375 test cases\n",
            "293/293 [==============================] - 15s 52ms/step - loss: 0.0617 - accuracy: 0.6283\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "done! have 7232 test cases\n",
            "226/226 [==============================] - 12s 52ms/step - loss: 0.0384 - accuracy: 0.7683\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "done! have 10756 test cases\n",
            "337/337 [==============================] - 7s 21ms/step - loss: 0.0525 - accuracy: 0.7166\n",
            "Test accuracy: 0.7166240215301514\n",
            "-------------STARTING EPOCH 12-------------\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "done! have 10282 test cases\n",
            "322/322 [==============================] - 17s 53ms/step - loss: 0.0332 - accuracy: 0.7244\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "done! have 10096 test cases\n",
            "316/316 [==============================] - 17s 53ms/step - loss: 0.0455 - accuracy: 0.7122\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "done! have 10874 test cases\n",
            "340/340 [==============================] - 18s 53ms/step - loss: 0.0405 - accuracy: 0.7855\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "done! have 10861 test cases\n",
            "340/340 [==============================] - 18s 52ms/step - loss: 0.0557 - accuracy: 0.5830\n",
            "40\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "done! have 10164 test cases\n",
            "318/318 [==============================] - 16s 51ms/step - loss: 0.0465 - accuracy: 0.7658\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "done! have 8788 test cases\n",
            "275/275 [==============================] - 14s 51ms/step - loss: 0.0414 - accuracy: 0.8204\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "done! have 10929 test cases\n",
            "342/342 [==============================] - 17s 51ms/step - loss: 0.0417 - accuracy: 0.7307\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "done! have 9229 test cases\n",
            "289/289 [==============================] - 15s 50ms/step - loss: 0.0460 - accuracy: 0.6774\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "done! have 6183 test cases\n",
            "194/194 [==============================] - 10s 51ms/step - loss: 0.0522 - accuracy: 0.6820\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "done! have 10322 test cases\n",
            "323/323 [==============================] - 16s 50ms/step - loss: 0.0442 - accuracy: 0.7139\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "done! have 10819 test cases\n",
            "339/339 [==============================] - 17s 50ms/step - loss: 0.0610 - accuracy: 0.6518\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "done! have 9375 test cases\n",
            "293/293 [==============================] - 15s 50ms/step - loss: 0.0615 - accuracy: 0.6321\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "done! have 7232 test cases\n",
            "226/226 [==============================] - 11s 50ms/step - loss: 0.0380 - accuracy: 0.7720\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "done! have 10756 test cases\n",
            "337/337 [==============================] - 7s 21ms/step - loss: 0.0522 - accuracy: 0.7191\n",
            "Test accuracy: 0.7191234827041626\n",
            "-------------STARTING EPOCH 13-------------\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "done! have 10282 test cases\n",
            "322/322 [==============================] - 16s 50ms/step - loss: 0.0340 - accuracy: 0.7224\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "done! have 10096 test cases\n",
            "316/316 [==============================] - 16s 50ms/step - loss: 0.0455 - accuracy: 0.7183\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "done! have 10874 test cases\n",
            "340/340 [==============================] - 17s 51ms/step - loss: 0.0403 - accuracy: 0.7870\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "done! have 10861 test cases\n",
            "340/340 [==============================] - 17s 51ms/step - loss: 0.0556 - accuracy: 0.5816\n",
            "40\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "done! have 10164 test cases\n",
            "318/318 [==============================] - 16s 51ms/step - loss: 0.0467 - accuracy: 0.7640\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "done! have 8788 test cases\n",
            "275/275 [==============================] - 14s 50ms/step - loss: 0.0417 - accuracy: 0.8206\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "done! have 10929 test cases\n",
            "342/342 [==============================] - 17s 51ms/step - loss: 0.0422 - accuracy: 0.7264\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "done! have 9229 test cases\n",
            "289/289 [==============================] - 14s 50ms/step - loss: 0.0458 - accuracy: 0.6769\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "done! have 6183 test cases\n",
            "194/194 [==============================] - 10s 50ms/step - loss: 0.0518 - accuracy: 0.6775\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "done! have 10322 test cases\n",
            "323/323 [==============================] - 16s 50ms/step - loss: 0.0442 - accuracy: 0.7141\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "done! have 10819 test cases\n",
            "339/339 [==============================] - 17s 50ms/step - loss: 0.0616 - accuracy: 0.6534\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "done! have 9375 test cases\n",
            "293/293 [==============================] - 15s 50ms/step - loss: 0.0617 - accuracy: 0.6290\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "done! have 7232 test cases\n",
            "226/226 [==============================] - 11s 50ms/step - loss: 0.0379 - accuracy: 0.7721\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "done! have 10756 test cases\n",
            "337/337 [==============================] - 7s 21ms/step - loss: 0.0528 - accuracy: 0.7171\n",
            "Test accuracy: 0.7170541882514954\n",
            "-------------STARTING EPOCH 14-------------\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "done! have 10282 test cases\n",
            "322/322 [==============================] - 16s 50ms/step - loss: 0.0338 - accuracy: 0.7211\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "done! have 10096 test cases\n",
            "316/316 [==============================] - 16s 50ms/step - loss: 0.0452 - accuracy: 0.7149\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "done! have 10874 test cases\n",
            "340/340 [==============================] - 17s 51ms/step - loss: 0.0404 - accuracy: 0.7853\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "done! have 10861 test cases\n",
            "340/340 [==============================] - 17s 51ms/step - loss: 0.0558 - accuracy: 0.5821\n",
            "40\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "done! have 10164 test cases\n",
            "318/318 [==============================] - 16s 50ms/step - loss: 0.0464 - accuracy: 0.7675\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOoguOvCdOGQ"
      },
      "source": [
        "\"\"\"\n",
        "#defining lstm model\n",
        "#rnn is later\n",
        "def build_LSTM_model():#vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = keras.Sequential(\n",
        "      [\n",
        "       layers.ConvLSTM2D(\n",
        "           filters=40,kernel_size=(3,3),padding='same',return_sequences=True\n",
        "       ),\n",
        "       layers.BatchNormalization(),\n",
        "       layers.ConvLSTM2D(\n",
        "           filters=40,kernel_size=(3,3),padding='same',return_sequences=True\n",
        "       ),\n",
        "       layers.BatchNormalization()\n",
        "       ])\n",
        "  model.compile(loss=keras.losses.MeanSquaredError(),optimizer='adam',metrics=[\"accuracy\"])\n",
        "  return model\n",
        "\n",
        "x = np.random.rand(1600,120,160,1)\n",
        "X = tf.convert_to_tensor(x)\n",
        "print(X.shape[0])\n",
        "\n",
        "\n",
        "rnn_model = build_LSTM_model()\n",
        "# Initialize the model by passing some data through\n",
        "predictions = rnn_model.predict(X)\n",
        "\n",
        "#print(predictions)\n",
        "# Print the summary of the layers in the model.\n",
        "print(rnn_model.summary())\n",
        "\n",
        "\n",
        "\n",
        "    # Layer 1: Embedding layer to transform indices into dense vectors \n",
        "    #   of a fixed embedding size\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
        "\n",
        "    # Layer 2: LSTM with `rnn_units` number of units. \n",
        "    # TODO: Call the LSTM function defined above to add this layer.\n",
        "    LSTM(rnn_units),\n",
        "\n",
        "    # Layer 3: Dense (fully-connected) layer that transforms the LSTM output\n",
        "    #   into the vocabulary size. \n",
        "    # TODO: Add the Dense layer.\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "\"\"\"\n",
        "\n",
        "  #return model\n",
        "\n",
        "# Build a simple model with default hyperparameters. You will get the \n",
        "#   chance to change these later.\n",
        "#model = build_model(len(vocab), embedding_dim=256, rnn_units=1024, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cINM9ewdY2V"
      },
      "source": [
        "#figure out batches w/ input data, set that up, break them down into 100 frames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPq2o3i0u3LT"
      },
      "source": [
        "\"\"\"\n",
        "# saving and loading the model weights\n",
        " \n",
        "# save model\n",
        "model.save_weights('gfgModelWeights')\n",
        "print('Model Saved!')\n",
        " \n",
        "# load model\n",
        "savedModel = model.load_weights('gfgModelWeights')\n",
        "print('Model Loaded!')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRfErGr4q0IA"
      },
      "source": [
        "\"\"\"import cv2\n",
        "import time\n",
        "from keyboard import is_pressed  # using module keyboard\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from grabscreen import grab_screen\n",
        "from skimage.color import rgb2gray\n",
        "import IPython.display as display\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Activation,Dropout,Flatten,Conv2D,MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "import vgamepad as vg\n",
        "\n",
        "def start(model_file_name):\n",
        "    gamepad = vg.VX360Gamepad()\n",
        "    cnn_model = tf.load_model(model_file_name)\n",
        "    print(cnn_model.summary)\n",
        "    #time_end = time_start + 10\n",
        "    avg_fps = []\n",
        "    time1 = time.time()\n",
        "    bool_val = True\n",
        "    i = 0\n",
        "    paused = False\n",
        "    data_array = []\n",
        "    counter = 0\n",
        "    while True:\n",
        "        if not paused:\n",
        "            screen = grab_screen(region=(0,0,1270,720))\n",
        "            \n",
        "            #plt.imshow(screen)\n",
        "            #plt.show()\n",
        "            screen = cv2.resize(screen, (160,120))\n",
        "            \n",
        "            gray_tensor = tf.convert_to_tensor(rgb2gray(screen))\n",
        "            \n",
        "            input_data_shape = list(gray_tensor.shape) + [1]\n",
        "            \n",
        "            gray_tensor_reshaped = tf.reshape(gray_tensor,input_data_shape)\n",
        "            \n",
        "            control_vector = cnn_model.predict(gray_tensor_reshaped)\n",
        "\n",
        "            lt = control_vector[0]\n",
        "            rt = control_vector[1]\n",
        "            ls = control_vector[2]\n",
        "\n",
        "            #modifying controls for vgamepad\n",
        "            ls = (ls - 0.5)*2\n",
        "            gamepad.left_trigger_float(lt)\n",
        "            gamepad.right_trigger_float(rt)\n",
        "            gamepad.left_joystick_float(x_value_float=ls)\n",
        "            gamepad.update()\n",
        "\n",
        "            time.sleep(0.0001)\n",
        "\n",
        "        if is_pressed('p'):\n",
        "            if paused:\n",
        "                paused = False\n",
        "                print('unpaused!')\n",
        "                time.sleep(1)\n",
        "            else:\n",
        "                print('Pausing!')\n",
        "                paused = True\n",
        "                time.sleep(1)\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"press q to start\")\n",
        "    while True:\n",
        "        if is_pressed('q'):\n",
        "            break\n",
        "    print(\"STARTING\")\n",
        "    start()\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwjrZOQmDSbN"
      },
      "source": [
        "\"\"\"\n",
        "colab macro saabaaaaaaaaaaaaaaaaaaaaaaaaaaaaassssssssssssssssssssssssssssssssssssdddddddddddddddddddddddddddddddddddddddddddddddddddddddaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaasaabaaaaaaaaaaaaaaaaaaaaaaaaaaaaassssssssssssssssssssssssssssssssssssdddddddddddddddddddddddddddddddddddddddddddddddddddddddaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaasaabaaaaaaaaaaaaaaaaaaaaaaaaaaaaassssssssssssssssssssssssssssssssssssdddddddddddddddddddddddddddddddddddddddddddddddddddddddaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaasaabaaaaaaaaaaaaaaaaaaaaaaaaaaaaassssssssssssssssssssssssssssssssssssdddddddddddddddddddddddddddddddddddddddddddddddddddddddaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaasaabaaaaaaaaaaaaaaaaaaaaaaaaaaaaassssssssssssssssssssssssssssssssssssdddddddddddddddddddddddddddddddddddddddddddddddddddddddaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaasaabaaaaaaaaaaaaaaaaaaaaaaaaaaaaassssssssssssssssssssssssssssssssssssdddddddddddddddddddddddddddddddddddddddddddddddddddddddaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaasaabaaaaaaaaaaaaaaaaaaaaaaaaaaaaassssssssssssssssssssssssssssssssssssdddddddddddddddddddddddddddddddddddddddddddddddddddddddaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaap\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkQnuYsPgrlO"
      },
      "source": [
        ""
      ]
    }
  ]
}