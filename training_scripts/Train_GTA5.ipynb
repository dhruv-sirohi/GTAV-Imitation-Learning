{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_GTA5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28fr9Fy1k8yH"
      },
      "source": [
        "Note: must turn off radar in settings before recording"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNkuehuqjPe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bf2f974-0216-4938-f9aa-5d6ee81b7d9c"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#imports + file upload\n",
        "print(\"need to prune imports\")\n",
        "#h+=1\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Activation,Dropout,Flatten,Conv2D,MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "assert len(tf.config.list_physical_devices('GPU')) > 0\n",
        "\n",
        "from google.colab import files\n",
        "from skimage.color import rgb2gray\n",
        "from collections import Counter\n",
        "from random import shuffle\n",
        "import cv2\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt \n",
        "#uploaded = files.upload()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "need to prune imports\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lu6X4MSkTQL"
      },
      "source": [
        "#data processing\n",
        "\n",
        "#next steps: use GAN to debias dataset (MIT 6.S191 lec 4, lab 2)\n",
        "\n",
        "def data_processing(start_val,num_files):\n",
        "  s_turn = []\n",
        "  m_turn = []\n",
        "  adj_turn = []\n",
        "  no_turn = []\n",
        "  balanced_data = []\n",
        "  starting_value = start_val\n",
        "  continue_loop = True\n",
        "  #start_time = time.time()\n",
        "  while continue_loop:\n",
        "    data_file_name = '/content/drive/MyDrive/GTA Driving Data/processed-training_data-{}.npy'.format(starting_value)\n",
        "    if os.path.isfile(data_file_name) and starting_value < start_val + num_files:\n",
        "      print(starting_value)\n",
        "      starting_value += 1\n",
        "      processed_data = np.load(data_file_name,allow_pickle=True)    \n",
        "      #print(len(processed_data))\n",
        "      #h+= 1\n",
        "      #i = 0\n",
        "      for entry in processed_data:\n",
        "        #print(i)\n",
        "        #i += 1\n",
        "        #np_entry =print(entry[0])\n",
        "        y = entry[0][0:3]\n",
        "        y_ls = y[2]\n",
        "        x= entry[1]\n",
        "        #x = rgb2gray(entry[1])\n",
        "        #flipping images\n",
        "        y_flipped = [y[0],y[1],1-y_ls]\n",
        "        x_flipped = cv2.flip(x, 1)\n",
        "        #print(y_ls)\n",
        "        if (y_ls > 0.875 or y_ls < 0.125):\n",
        "          #very sharp turn, but it doesn't warrant its own array\n",
        "          s_turn.append([x,y])\n",
        "          #s_turn.append([x_flipped,y_flipped])\n",
        "        elif (y_ls > 0.8 or y_ls < 0.2):\n",
        "          #sharp turn\n",
        "          #s_turn.append([x_flipped,y_flipped])\n",
        "          s_turn.append([x,y])\n",
        "        elif (y_ls > 0.7 or y_ls < 0.3):\n",
        "          #medium turn\n",
        "          m_turn.append([x,y])\n",
        "          #m_turn.append([x_flipped,y_flipped])\n",
        "\n",
        "        elif (y_ls > 0.65 or y_ls < 0.35):\n",
        "          #light turn, doesn't warrant its own array\n",
        "          m_turn.append([x,y])\n",
        "          #m_turn.append([x_flipped,y_flipped])\n",
        "\n",
        "        elif (y_ls > 0.575 or y_ls < 0.425):\n",
        "          #adjustments\n",
        "          adj_turn.append([x,y])\n",
        "          #adj_turn.append([x_flipped,y_flipped])\n",
        "        else:\n",
        "          #no turn\n",
        "          no_turn.append([x,y])\n",
        "          #no_turn.append([x_flipped,y_flipped])\n",
        "    else:\n",
        "      if not (starting_value < start_val + num_files):\n",
        "        continue_loop = False\n",
        "      else:\n",
        "        starting_value += 1\n",
        "\n",
        "  shuffle(no_turn)\n",
        "  #without shuffling, array adjustment in next step would mean that the training set is full of mirror repeats \n",
        "  #we would prefer to have [img12_mirrored,img1] rather than [img1_mirrored, img1]\n",
        "  #shuffling allows for this\n",
        "\n",
        "  balanced_data = s_turn + m_turn + adj_turn + no_turn[0:len(adj_turn)]\n",
        "  #we want agent to make small adjustments, so adj_turn isn't being adjusted\n",
        "  #we don't want agent to just go straight, so less of no_turn is being added\n",
        "  \n",
        "\n",
        "  \"\"\"\n",
        "  arr_lengths = [len(adj_turn),len(adj_turn),len(m_turn),len(s_turn)]\n",
        "  arr_names = [\"no turn (trimmed)\",\"adjustment turn\",\"medium turn\", \"sharp turn\"]\n",
        "  \n",
        "  plt.bar(arr_names,arr_lengths)\n",
        "  plt.show()\n",
        "  \"\"\"\n",
        "\n",
        "  no_turn = []\n",
        "  s_turn = []\n",
        "  m_turn = []\n",
        "  adj_turn = []\n",
        "  shuffle(balanced_data)\n",
        "  X = []\n",
        "  Y = []\n",
        "  for entry in balanced_data:\n",
        "    entry[0] = rgb2gray(entry[0])\n",
        "\n",
        "\n",
        "  X , Y = zip(*balanced_data)\n",
        "\n",
        "  print(\"done! have {} test cases\".format(len(balanced_data)))\n",
        "  #print(\"time to run time: {}\".format(time.time()-start_time))\n",
        "  balanced_data = []\n",
        "\n",
        "  X_train_3dim = tf.convert_to_tensor(X)\n",
        "  new_shape = list(X_train_3dim.shape) + [1]\n",
        "  X_train = tf.reshape(X_train_3dim,new_shape)\n",
        "\n",
        "  Y_train_3dim = tf.convert_to_tensor(Y)\n",
        "  new_shape = list(Y_train_3dim.shape) + [1]\n",
        "  Y_train = tf.transpose(tf.reshape(Y_train_3dim,new_shape),perm = [0,2,1])\n",
        "  \n",
        "  return X_train,Y_train"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SzgDspAwdbu"
      },
      "source": [
        "#saving chunk of training data as testing data (now irrelevant)\n",
        "\n",
        "#PERCENT_TEST = 20\n",
        "\n",
        "#test_index_start = int(PERCENT_TEST*len(balanced_data)/100)\n",
        "#train_data = balanced_data[:-test_index_start]\n",
        "#test_data = balanced_data[-test_index_start:]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwYKIJtKtsPl"
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "import mxnet as mx\n",
        "from mxnet import np, npx\n",
        "from mxnet.gluon import nn\n",
        "from d2l import mxnet as d2l\n",
        "\"\"\"\n",
        "\n",
        "#set up alexnet\n",
        "\n",
        "\n",
        "def build_alexnet_model():\n",
        "  #image_shape = (80,60,1)\n",
        "  np.random.seed(1000)\n",
        "  #https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputLayer\n",
        "  model = tf.keras.Sequential([\n",
        "    #tf.keras.layers.InputLayer(input_shape=image_shape),\n",
        "    tf.keras.layers.Conv2D(filters=96, kernel_size=(5,5),strides=(2,2),activation=tf.nn.relu), \n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(3,3),strides=(2,2)),\n",
        "    tf.keras.layers.Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),activation=tf.nn.relu), \n",
        "    #tf.keras.layers.MaxPooling2D(pool_size=(3,3),strides=(2,2)),\n",
        "    #tf.keras.layers.Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),activation=tf.nn.relu), \n",
        "    tf.keras.layers.Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),activation=tf.nn.relu), \n",
        "    tf.keras.layers.Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),activation=tf.nn.relu), \n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(3,3),strides=(2,2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(4096, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(4096, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(3, activation=tf.keras.activations.linear)])\n",
        "  \n",
        "  return model\n",
        "\n",
        "def build_cnn_model():\n",
        "      cnn_model = tf.keras.Sequential([\n",
        "        # Here, we use a larger 11 x 11 window to capture objects. At the same\n",
        "        # time, we use a stride of 2 to reduce the height and width of\n",
        "        # the output.\n",
        "        tf.keras.layers.Conv2D(filters=96, kernel_size=11, strides=2),\n",
        "        tf.keras.layers.Activation('relu'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
        "        #tf.keras.layers.BatchNormalization(axis=3),\n",
        "        # Make the convolution window smaller, set padding to 2 for consistent\n",
        "        # height and width across the input and output, and increase the\n",
        "        # number of output channels\n",
        "        tf.keras.layers.Conv2D(filters=256, kernel_size=5, padding='same',\n",
        "                               activation='relu'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
        "        #tf.keras.layers.BatchNormalization(),\n",
        "        # Use three successive convolutional layers and a smaller convolution\n",
        "        # window. Except for the final convolutional layer, the number of\n",
        "        # output channels is further increased. Pooling layers are not used to\n",
        "        # reduce the height and width of input after the first two\n",
        "        # convolutional layers\n",
        "        tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding='same',\n",
        "                               activation='relu'),\n",
        "        #tf.keras.layers.BatchNormalization(axis=-1),\n",
        "        tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding='same',\n",
        "                               activation='relu'),\n",
        "        #tf.keras.layers.BatchNormalization(axis=-1),\n",
        "        tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same',\n",
        "                               activation='relu'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
        "        #tf.keras.layers.BatchNormalization(axis=-1),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        #tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(4096, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(4096, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        # Output layer. Because control vector is made up of 3 values, \n",
        "        # this dense layer is made up of only 3 units\n",
        "        tf.keras.layers.Dense(3)])\n",
        "      \n",
        "      return cnn_model\n",
        "\n",
        "\n",
        "#x = np.random.rand(2,160,120,1)\n",
        "#X = tf.convert_to_tensor(x)\n",
        "\n",
        "# Initialize the model by passing some data through\n",
        "#predictions = cnn_model.predict(X_train_0)\n",
        "#print(predictions)\n",
        "#print(predictions.shape)\n",
        "# Print the summary of the layers in the model.\n",
        "#print(cnn_model.summary())\n",
        "\n",
        "#load cnn model, load arrays\n",
        "time_vals = []\n",
        "train_accuracy = []\n",
        "test_accuracy = []\n",
        "\n",
        "epoch_to_load = int(input(\"which epoch to load?\"))\n",
        "if epoch_to_load > 0:\n",
        "  cnn_model = load_weights('/content/drive/MyDrive/GTA Driving Data/training weights/gta_cnn_model_epoch_{}.h5'.format(epoch_to_load))\n",
        "  graph_data = np.load('/content/drive/MyDrive/GTA Driving Data/progress data/graph_data.npy',allow_pickle=True)\n",
        "  time_vals = graph_data[0][0:epoch_to_load]\n",
        "  train_accuracy = graph_data[1][0:epoch_to_load]\n",
        "  test_accuracy = graph_data[2][0:epoch_to_load]\n",
        "\n",
        "else:\n",
        "  cnn_model = build_cnn_model()\n",
        "  cnn_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-1), \n",
        "                loss=tf.keras.losses.MeanSquaredError(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "\n",
        "files_in_epoch = 0\n",
        "accuracy_store = 0\n",
        "start_val = 0\n",
        "num_files_to_retrieve = 10\n",
        "num_files_to_test = 200\n",
        "for epoch in range(epoch_to_load+1,EPOCHS+1):\n",
        "  print('-------------STARTING EPOCH {}-------------'.format(epoch))\n",
        "  files_in_epoch = 0\n",
        "  accuracy_store = 0\n",
        "  while start_val < num_files_to_test-num_files_to_retrieve*3:\n",
        "    if(start_val < 83):\n",
        "      X_train, Y_train = data_processing(start_val,num_files_to_retrieve)\n",
        "      #print(\"len {}\".format(len(X_train)))\n",
        "      start_val += num_files_to_retrieve\n",
        "    else:\n",
        "      X_train, Y_train = data_processing(start_val,num_files_to_retrieve*3)\n",
        "      start_val += num_files_to_retrieve*3\n",
        "    \n",
        "    num_files = X_train.shape[0]\n",
        "    files_in_epoch += num_files\n",
        "\n",
        "    history = cnn_model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=1)#,callbacks=[cp_callback])\n",
        "    #weights accuracy by number of files it is measured over\n",
        "    group_accuracy = num_files*history.history['accuracy'][0]\n",
        "    accuracy_store += group_accuracy  \n",
        "\n",
        "  #train on tail end of dataset\n",
        "  X_train, Y_train = data_processing(start_val,num_files_to_test-start_val+1)\n",
        "\n",
        "  num_files = X_train.shape[0]\n",
        "  files_in_epoch += num_files\n",
        "\n",
        "  history = cnn_model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=1)#,callbacks=[cp_callback])\n",
        "  \n",
        "  group_accuracy = num_files*history.history['accuracy'][0]\n",
        "  accuracy_store += group_accuracy\n",
        "\n",
        "  #appends average epoch accuracy\n",
        "  train_accuracy.append(accuracy_store/(files_in_epoch))\n",
        "  time_vals.append(epoch)\n",
        "\n",
        "  X_test, Y_test = data_processing(201,33)\n",
        "  test_loss, test_acc = cnn_model.evaluate(X_test,Y_test)\n",
        "  print('Test accuracy:', test_acc)\n",
        "  test_accuracy.append(test_acc)\n",
        "\n",
        "  #saving model\n",
        "  if epoch % 5 == 0:\n",
        "    print(\"SAVED\")\n",
        "    file_name = \"/content/drive/MyDrive/GTA Driving Data/training weights/gta_cnn_model_epoch_{}.h5\".format(epoch)\n",
        "    cnn_model.save(file_name)\n",
        "    graph_data = [time_vals,train_accuracy,test_accuracy]\n",
        "    np.save('/content/drive/MyDrive/GTA Driving Data/progress data/graph_data.npy',graph_data)\n",
        "  \n",
        "  start_val = 0\n",
        "\n",
        "plt.plot(time_vals, test_accuracy, label = \"test accuracy\")\n",
        "plt.plot(time_vals, train_accuracy, label = \"train accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOoguOvCdOGQ"
      },
      "source": [
        "\"\"\"\n",
        "#defining lstm model\n",
        "#rnn is later\n",
        "def build_LSTM_model():#vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = keras.Sequential(\n",
        "      [\n",
        "       layers.ConvLSTM2D(\n",
        "           filters=40,kernel_size=(3,3),padding='same',return_sequences=True\n",
        "       ),\n",
        "       layers.BatchNormalization(),\n",
        "       layers.ConvLSTM2D(\n",
        "           filters=40,kernel_size=(3,3),padding='same',return_sequences=True\n",
        "       ),\n",
        "       layers.BatchNormalization()\n",
        "       ])\n",
        "  model.compile(loss=keras.losses.MeanSquaredError(),optimizer='adam',metrics=[\"accuracy\"])\n",
        "  return model\n",
        "\n",
        "x = np.random.rand(1600,120,160,1)\n",
        "X = tf.convert_to_tensor(x)\n",
        "print(X.shape[0])\n",
        "\n",
        "\n",
        "rnn_model = build_LSTM_model()\n",
        "# Initialize the model by passing some data through\n",
        "predictions = rnn_model.predict(X)\n",
        "\n",
        "#print(predictions)\n",
        "# Print the summary of the layers in the model.\n",
        "print(rnn_model.summary())\n",
        "\n",
        "\n",
        "\n",
        "    # Layer 1: Embedding layer to transform indices into dense vectors \n",
        "    #   of a fixed embedding size\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
        "\n",
        "    # Layer 2: LSTM with `rnn_units` number of units. \n",
        "    # TODO: Call the LSTM function defined above to add this layer.\n",
        "    LSTM(rnn_units),\n",
        "\n",
        "    # Layer 3: Dense (fully-connected) layer that transforms the LSTM output\n",
        "    #   into the vocabulary size. \n",
        "    # TODO: Add the Dense layer.\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "\"\"\"\n",
        "\n",
        "  #return model\n",
        "\n",
        "# Build a simple model with default hyperparameters. You will get the \n",
        "#   chance to change these later.\n",
        "#model = build_model(len(vocab), embedding_dim=256, rnn_units=1024, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cINM9ewdY2V"
      },
      "source": [
        "#figure out batches w/ input data, set that up, break them down into 100 frames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPq2o3i0u3LT"
      },
      "source": [
        "\"\"\"\n",
        "# saving and loading the model weights\n",
        " \n",
        "# save model\n",
        "model.save_weights('gfgModelWeights')\n",
        "print('Model Saved!')\n",
        " \n",
        "# load model\n",
        "savedModel = model.load_weights('gfgModelWeights')\n",
        "print('Model Loaded!')\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkQnuYsPgrlO"
      },
      "source": [
        ""
      ]
    }
  ]
}